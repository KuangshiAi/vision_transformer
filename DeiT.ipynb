{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qC37pBE4cr7",
        "outputId": "c5e3febb-5f30-4a08-84aa-d84e0acfb304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rSwtDub4Nl7"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCIFMx0T4Nl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ee2b46-8506-4be0-958a-9e53ffe10589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "tf.keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zYh3UlR4Nl9"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhIbk1oX4Nl9"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "MODEL_TYPE = \"deit_distilled_tiny_patch16_224\"\n",
        "RESOLUTION = 224\n",
        "PATCH_SIZE = 16\n",
        "NUM_PATCHES = (RESOLUTION // PATCH_SIZE) ** 2\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 192\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 12\n",
        "MLP_UNITS = [\n",
        "    PROJECTION_DIM * 4,\n",
        "    PROJECTION_DIM,\n",
        "]\n",
        "DROPOUT_RATE = 0.0\n",
        "DROP_PATH_RATE = 0.1\n",
        "\n",
        "# Training\n",
        "NUM_EPOCHS = 50\n",
        "BASE_LR = 0.0005\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "# Data\n",
        "BATCH_SIZE = 256\n",
        "AUTO = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN6QfHAw4Nl-"
      },
      "source": [
        "## Load the `tf_flowers` dataset and prepare preprocessing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc3MA7Zc4Nl_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_dataset(is_training=True):\n",
        "    def fn(image, label):\n",
        "        if is_training:\n",
        "            # Resize to a bigger spatial resolution and take the random\n",
        "            # crops.\n",
        "            image = tf.image.resize(image, (RESOLUTION + 20, RESOLUTION + 20))\n",
        "            image = tf.image.random_crop(image, (RESOLUTION, RESOLUTION, 3))\n",
        "            image = tf.image.random_flip_left_right(image)\n",
        "        else:\n",
        "            image = tf.image.resize(image, (RESOLUTION, RESOLUTION))\n",
        "        label = tf.one_hot(label, depth=NUM_CLASSES)\n",
        "        return image, label\n",
        "\n",
        "    return fn\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset, is_training=True):\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(BATCH_SIZE * 10)\n",
        "    dataset = dataset.map(preprocess_dataset(is_training), num_parallel_calls=AUTO)\n",
        "    return dataset.batch(BATCH_SIZE).prefetch(AUTO)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5\n",
        "train_dataset, val_dataset = tfds.load(\n",
        "    \"tf_flowers\", split=[\"train[:90%]\", \"train[90%:]\"], as_supervised=True\n",
        ")\n",
        "num_train = train_dataset.cardinality()\n",
        "num_val = val_dataset.cardinality()\n",
        "print(f\"Number of training examples: {num_train}\")\n",
        "print(f\"Number of validation examples: {num_val}\")\n",
        "\n",
        "train_dataset = prepare_dataset(train_dataset, is_training=True)\n",
        "val_dataset = prepare_dataset(val_dataset, is_training=False)"
      ],
      "metadata": {
        "id": "dfiyZ6h0Mg_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6sn2ncw4Nl_"
      },
      "source": [
        "## Implementing the DeiT variants of ViT\n",
        "\n",
        "Since DeiT is an extension of ViT it'd make sense to first implement ViT and then extend\n",
        "it to support DeiT's components.\n",
        "\n",
        "First, we'll implement a layer for Stochastic Depth\n",
        "([Huang et al.](https://arxiv.org/abs/1603.09382))\n",
        "which is used in DeiT for regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ1WjLd54Nl_"
      },
      "outputs": [],
      "source": [
        "# Referred from: github.com:rwightman/pytorch-image-models.\n",
        "class StochasticDepth(layers.Layer):\n",
        "    def __init__(self, drop_prop, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.drop_prob = drop_prop\n",
        "\n",
        "    def call(self, x, training=True):\n",
        "        if training:\n",
        "            keep_prob = 1 - self.drop_prob\n",
        "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
        "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
        "            random_tensor = tf.floor(random_tensor)\n",
        "            return (x / keep_prob) * random_tensor\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55J5kvDH4NmA"
      },
      "source": [
        "Now, we'll implement the MLP and Transformer blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZdTWzrd4NmA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def mlp(x, dropout_rate: float, hidden_units: List):\n",
        "    \"\"\"FFN for a Transformer block.\"\"\"\n",
        "    # Iterate over the hidden units and\n",
        "    # add Dense => Dropout.\n",
        "    for (idx, units) in enumerate(hidden_units):\n",
        "        x = layers.Dense(\n",
        "            units,\n",
        "            activation=tf.nn.gelu if idx == 0 else None,\n",
        "        )(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transformer(drop_prob: float, name: str) -> keras.Model:\n",
        "    \"\"\"Transformer block with pre-norm.\"\"\"\n",
        "    num_patches = NUM_PATCHES + 2 if \"distilled\" in MODEL_TYPE else NUM_PATCHES + 1\n",
        "    encoded_patches = layers.Input((num_patches, PROJECTION_DIM))\n",
        "\n",
        "    # Layer normalization 1.\n",
        "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(encoded_patches)\n",
        "\n",
        "    # Multi Head Self Attention layer 1.\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS,\n",
        "        key_dim=PROJECTION_DIM,\n",
        "        dropout=DROPOUT_RATE,\n",
        "    )(x1, x1)\n",
        "    attention_output = (\n",
        "        StochasticDepth(drop_prob)(attention_output) if drop_prob else attention_output\n",
        "    )\n",
        "\n",
        "    # Skip connection 1.\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "    # Layer normalization 2.\n",
        "    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
        "\n",
        "    # MLP layer 1.\n",
        "    x4 = mlp(x3, hidden_units=MLP_UNITS, dropout_rate=DROPOUT_RATE)\n",
        "    x4 = StochasticDepth(drop_prob)(x4) if drop_prob else x4\n",
        "\n",
        "    # Skip connection 2.\n",
        "    outputs = layers.Add()([x2, x4])\n",
        "\n",
        "    return keras.Model(encoded_patches, outputs, name=name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRdsjao64NmA"
      },
      "source": [
        "We'll now implement a `ViTClassifier` class building on top of the components we just\n",
        "developed. Here we'll be following the original pooling strategy used in the ViT paper --\n",
        "use a class token and use the feature representations corresponding to it for\n",
        "classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdYXgi424NmB"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ViTClassifier(keras.Model):\n",
        "    \"\"\"Vision Transformer base class.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Patchify + linear projection + reshaping.\n",
        "        self.projection = keras.Sequential(\n",
        "            [\n",
        "                layers.Conv2D(\n",
        "                    filters=PROJECTION_DIM,\n",
        "                    kernel_size=(PATCH_SIZE, PATCH_SIZE),\n",
        "                    strides=(PATCH_SIZE, PATCH_SIZE),\n",
        "                    padding=\"VALID\",\n",
        "                    name=\"conv_projection\",\n",
        "                ),\n",
        "                layers.Reshape(\n",
        "                    target_shape=(NUM_PATCHES, PROJECTION_DIM),\n",
        "                    \n",
        "                ),\n",
        "            ],\n",
        "            name=\"projection\",\n",
        "        )\n",
        "\n",
        "        # Positional embedding.\n",
        "        init_shape = (\n",
        "            1,\n",
        "            NUM_PATCHES + 1,\n",
        "            PROJECTION_DIM,\n",
        "        )\n",
        "        self.positional_embedding = tf.Variable(\n",
        "            tf.zeros(init_shape), name=\"pos_embedding\"\n",
        "        )\n",
        "\n",
        "        # Transformer blocks.\n",
        "        dpr = [x for x in tf.linspace(0.0, DROP_PATH_RATE, NUM_LAYERS)]\n",
        "        self.transformer_blocks = [\n",
        "            transformer(drop_prob=dpr[i], name=f\"transformer_block_{i}\")\n",
        "            for i in range(NUM_LAYERS)\n",
        "        ]\n",
        "\n",
        "        # CLS token.\n",
        "        initial_value = tf.zeros((1, 1, PROJECTION_DIM))\n",
        "        self.cls_token = tf.Variable(\n",
        "            initial_value=initial_value, trainable=True, name=\"cls\"\n",
        "        )\n",
        "\n",
        "        # Other layers.\n",
        "        self.dropout = layers.Dropout(DROPOUT_RATE)\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n",
        "        self.head = layers.Dense(\n",
        "            NUM_CLASSES,\n",
        "            name=\"classification_head\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        n = tf.shape(inputs)[0]\n",
        "\n",
        "        # Create patches and project the patches.\n",
        "        projected_patches = self.projection(inputs)\n",
        "\n",
        "        # Append class token if needed.\n",
        "        cls_token = tf.tile(self.cls_token, (n, 1, 1))\n",
        "        cls_token = tf.cast(cls_token, projected_patches.dtype)\n",
        "        projected_patches = tf.concat([cls_token, projected_patches], axis=1)\n",
        "        print(projected_patches.shape)\n",
        "        print(self.positional_embedding.shape)\n",
        "\n",
        "        # Add positional embeddings to the projected patches.\n",
        "        encoded_patches = (\n",
        "            self.positional_embedding + projected_patches\n",
        "        )  # (B, number_patches, projection_dim)\n",
        "        encoded_patches = self.dropout(encoded_patches)\n",
        "\n",
        "        # Iterate over the number of layers and stack up blocks of\n",
        "        # Transformer.\n",
        "        for transformer_module in self.transformer_blocks:\n",
        "            # Add a Transformer block.\n",
        "            print(1)\n",
        "            encoded_patches = transformer_module(encoded_patches)\n",
        "\n",
        "        # Final layer normalization.\n",
        "        representation = self.layer_norm(encoded_patches)\n",
        "\n",
        "        # Pool representation.\n",
        "        encoded_patches = representation[:, 0]\n",
        "\n",
        "        # Classification head.\n",
        "        output = self.head(encoded_patches)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6xssvd14NmC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ViTDistilled(ViTClassifier):\n",
        "    def __init__(self, regular_training=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_tokens = 2\n",
        "        self.regular_training = regular_training\n",
        "\n",
        "        # CLS and distillation tokens, positional embedding.\n",
        "        init_value = tf.zeros((1, 1, PROJECTION_DIM))\n",
        "        self.dist_token = tf.Variable(init_value, name=\"dist_token\")\n",
        "        self.positional_embedding = tf.Variable(\n",
        "            tf.zeros(\n",
        "                (\n",
        "                    1,\n",
        "                    NUM_PATCHES + self.num_tokens,\n",
        "                    PROJECTION_DIM,\n",
        "                )\n",
        "            ),\n",
        "            name=\"pos_embedding\",\n",
        "        )\n",
        "\n",
        "        # Head layers.\n",
        "        self.head = layers.Dense(\n",
        "            NUM_CLASSES,\n",
        "            name=\"classification_head\",\n",
        "        )\n",
        "        self.head_dist = layers.Dense(\n",
        "            NUM_CLASSES,\n",
        "            name=\"distillation_head\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        n = tf.shape(inputs)[0]\n",
        "\n",
        "        # Create patches and project the patches.\n",
        "        projected_patches = self.projection(inputs)\n",
        "\n",
        "        # Append the tokens.\n",
        "        cls_token = tf.tile(self.cls_token, (n, 1, 1))\n",
        "        dist_token = tf.tile(self.dist_token, (n, 1, 1))\n",
        "        cls_token = tf.cast(cls_token, projected_patches.dtype)\n",
        "        dist_token = tf.cast(dist_token, projected_patches.dtype)\n",
        "        projected_patches = tf.concat(\n",
        "            [cls_token, dist_token, projected_patches], axis=1\n",
        "        )\n",
        "\n",
        "        # Add positional embeddings to the projected patches.\n",
        "        encoded_patches = (\n",
        "            self.positional_embedding + projected_patches\n",
        "        )  # (B, number_patches, projection_dim)\n",
        "        encoded_patches = self.dropout(encoded_patches)\n",
        "\n",
        "        # Iterate over the number of layers and stack up blocks of\n",
        "        # Transformer.\n",
        "        for transformer_module in self.transformer_blocks:\n",
        "            # Add a Transformer block.\n",
        "            encoded_patches = transformer_module(encoded_patches)\n",
        "\n",
        "        # Final layer normalization.\n",
        "        representation = self.layer_norm(encoded_patches)\n",
        "\n",
        "        # Classification heads.\n",
        "        x, x_dist = (\n",
        "            self.head(representation[:, 0]),\n",
        "            self.head_dist(representation[:, 1]),\n",
        "        )\n",
        "\n",
        "        if not training or self.regular_training:\n",
        "            # During standard train / finetune, inference average the classifier\n",
        "            # predictions.\n",
        "            return (x + x_dist) / 2\n",
        "\n",
        "        elif training:\n",
        "            # Only return separate classification predictions when training in distilled\n",
        "            # mode.\n",
        "            return x, x_dist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzGhyyUA4NmC"
      },
      "source": [
        "Let's verify if the `ViTDistilled` class can be initialized and called as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAf8o6lw4NmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195e8149-34f2-44f4-e4fd-db708e3f4163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 5)\n"
          ]
        }
      ],
      "source": [
        "NUM_CLASSES = 5\n",
        "deit_tiny_distilled = ViTDistilled()\n",
        "\n",
        "dummy_inputs = tf.ones((2, 224, 224, 3))\n",
        "outputs = deit_tiny_distilled(dummy_inputs, training=False)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvARy-2M4NmD"
      },
      "source": [
        "## Implementing the trainer\n",
        "\n",
        "Unlike what happens in standard knowledge distillation\n",
        "([Hinton et al.](https://arxiv.org/abs/1503.02531)),\n",
        "where a temperature-scaled softmax is used as well as KL divergence,\n",
        "DeiT authors use the following loss function:\n",
        "\n",
        "![](https://i.imgur.com/bXdxsBq.png)\n",
        "\n",
        "\n",
        "Here,\n",
        "\n",
        "* CE is cross-entropy\n",
        "* `psi` is the softmax function\n",
        "* Z_s denotes student predictions\n",
        "* y denotes true labels\n",
        "* y_t denotes teacher predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDSlK1N64NmE"
      },
      "outputs": [],
      "source": [
        "# use \"hard\" label distillation study\n",
        "class DeiT(keras.Model):\n",
        "    # Reference:\n",
        "    # https://keras.io/examples/vision/knowledge_distillation/\n",
        "    def __init__(self, student, teacher, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.student = student\n",
        "        self.teacher = teacher\n",
        "\n",
        "        self.student_loss_tracker = keras.metrics.Mean(name=\"student_loss\")\n",
        "        self.dist_loss_tracker = keras.metrics.Mean(name=\"distillation_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        metrics = super().metrics\n",
        "        metrics.append(self.student_loss_tracker)\n",
        "        metrics.append(self.dist_loss_tracker)\n",
        "        return metrics\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "    ):\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data.\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = tf.nn.softmax(self.teacher(x, training=False), -1)\n",
        "        teacher_predictions = tf.argmax(teacher_predictions, -1)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student.\n",
        "            cls_predictions, dist_predictions = self.student(x / 255.0, training=True)\n",
        "\n",
        "            # Compute losses.\n",
        "            student_loss = self.student_loss_fn(y, cls_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                teacher_predictions, dist_predictions\n",
        "            )\n",
        "            loss = (student_loss + distillation_loss) / 2\n",
        "\n",
        "        # Compute gradients.\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights.\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        student_predictions = (cls_predictions + dist_predictions) / 2\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "        self.dist_loss_tracker.update_state(distillation_loss)\n",
        "        self.student_loss_tracker.update_state(student_loss)\n",
        "\n",
        "        # Return a dict of performance.\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data.\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions.\n",
        "        y_prediction = self.student(x / 255.0, training=False)\n",
        "\n",
        "        # Calculate the loss.\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "        self.student_loss_tracker.update_state(student_loss)\n",
        "\n",
        "        # Return a dict of performance.\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        return results\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.student(inputs / 255.0, training=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcYt47fU4NmF"
      },
      "source": [
        "## Load the teacher model\n",
        "\n",
        "This model is based on the BiT family of ResNets\n",
        "([Kolesnikov et al.](https://arxiv.org/abs/1912.11370))\n",
        "fine-tuned on the `tf_flowers` dataset. You can refer to\n",
        "[this notebook](https://github.com/sayakpaul/deit-tf/blob/main/notebooks/bit-teacher.ipynb)\n",
        "to know how the training was performed. The teacher model has about 212 Million parameters\n",
        "which is about **40x more** than the student."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdmseIy-4NmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051e0b31-ac30-42be-d66d-9650709c5475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace bit_teacher_flowers/keras_metadata.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget -q https://github.com/sayakpaul/deit-tf/releases/download/v0.1.0/bit_teacher_flowers.zip\n",
        "!unzip -q bit_teacher_flowers.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bit_teacher_flowers = keras.models.load_model(\"bit_teacher_flowers\")"
      ],
      "metadata": {
        "id": "JXPupOu60GrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQpehYI24NmG"
      },
      "source": [
        "## Training through distillation (On TF_Flowers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRu3cfvd4NmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3f188f-5be9-4b6b-8e5d-bb4d8b5444fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "13/13 [==============================] - 69s 3s/step - accuracy: 0.1962 - student_loss: 2.0548 - distillation_loss: 2.0392 - val_accuracy: 0.2698 - val_student_loss: 1.6100 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.2492 - student_loss: 1.6371 - distillation_loss: 1.6487 - val_accuracy: 0.1907 - val_student_loss: 1.6193 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.2449 - student_loss: 1.6189 - distillation_loss: 1.6017 - val_accuracy: 0.1907 - val_student_loss: 1.6204 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.2501 - student_loss: 1.6064 - distillation_loss: 1.5958 - val_accuracy: 0.2480 - val_student_loss: 1.6011 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.2628 - student_loss: 1.5966 - distillation_loss: 1.5948 - val_accuracy: 0.3052 - val_student_loss: 1.5957 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.2909 - student_loss: 1.5882 - distillation_loss: 1.5867 - val_accuracy: 0.1880 - val_student_loss: 1.5839 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.3215 - student_loss: 1.5567 - distillation_loss: 1.5615 - val_accuracy: 0.2861 - val_student_loss: 1.5386 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.3890 - student_loss: 1.4600 - distillation_loss: 1.4408 - val_accuracy: 0.4142 - val_student_loss: 1.4537 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.4454 - student_loss: 1.3881 - distillation_loss: 1.3183 - val_accuracy: 0.4360 - val_student_loss: 1.3904 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.4596 - student_loss: 1.3324 - distillation_loss: 1.2560 - val_accuracy: 0.4251 - val_student_loss: 1.3546 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.4817 - student_loss: 1.2856 - distillation_loss: 1.1933 - val_accuracy: 0.5313 - val_student_loss: 1.2867 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.5422 - student_loss: 1.2303 - distillation_loss: 1.1167 - val_accuracy: 0.5504 - val_student_loss: 1.2101 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.5531 - student_loss: 1.2189 - distillation_loss: 1.1007 - val_accuracy: 0.5450 - val_student_loss: 1.2214 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.5771 - student_loss: 1.1907 - distillation_loss: 1.0699 - val_accuracy: 0.5886 - val_student_loss: 1.1562 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.5825 - student_loss: 1.1594 - distillation_loss: 1.0365 - val_accuracy: 0.5722 - val_student_loss: 1.1923 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.5898 - student_loss: 1.1516 - distillation_loss: 1.0193 - val_accuracy: 0.5586 - val_student_loss: 1.1290 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6052 - student_loss: 1.1248 - distillation_loss: 0.9883 - val_accuracy: 0.6104 - val_student_loss: 1.1310 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6270 - student_loss: 1.1023 - distillation_loss: 0.9532 - val_accuracy: 0.5995 - val_student_loss: 1.1380 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6076 - student_loss: 1.1314 - distillation_loss: 0.9956 - val_accuracy: 0.5695 - val_student_loss: 1.1645 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6094 - student_loss: 1.1216 - distillation_loss: 0.9803 - val_accuracy: 0.5695 - val_student_loss: 1.1021 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6325 - student_loss: 1.0818 - distillation_loss: 0.9299 - val_accuracy: 0.6240 - val_student_loss: 1.0487 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6337 - student_loss: 1.0800 - distillation_loss: 0.9233 - val_accuracy: 0.6213 - val_student_loss: 1.0694 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6500 - student_loss: 1.0593 - distillation_loss: 0.8942 - val_accuracy: 0.5940 - val_student_loss: 1.1197 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6527 - student_loss: 1.0486 - distillation_loss: 0.8875 - val_accuracy: 0.6185 - val_student_loss: 1.0385 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6627 - student_loss: 1.0321 - distillation_loss: 0.8563 - val_accuracy: 0.6240 - val_student_loss: 1.0551 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6667 - student_loss: 1.0276 - distillation_loss: 0.8554 - val_accuracy: 0.6158 - val_student_loss: 1.0774 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6748 - student_loss: 1.0193 - distillation_loss: 0.8426 - val_accuracy: 0.6213 - val_student_loss: 1.0490 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6773 - student_loss: 1.0157 - distillation_loss: 0.8405 - val_accuracy: 0.6185 - val_student_loss: 1.1132 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6761 - student_loss: 1.0057 - distillation_loss: 0.8303 - val_accuracy: 0.6431 - val_student_loss: 1.0272 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6921 - student_loss: 0.9867 - distillation_loss: 0.8002 - val_accuracy: 0.6567 - val_student_loss: 1.0096 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6942 - student_loss: 0.9928 - distillation_loss: 0.8058 - val_accuracy: 0.6349 - val_student_loss: 1.0424 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6912 - student_loss: 0.9996 - distillation_loss: 0.8230 - val_accuracy: 0.6213 - val_student_loss: 1.0760 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.6975 - student_loss: 0.9719 - distillation_loss: 0.7762 - val_accuracy: 0.6485 - val_student_loss: 0.9885 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7051 - student_loss: 0.9489 - distillation_loss: 0.7465 - val_accuracy: 0.6594 - val_student_loss: 0.9919 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7036 - student_loss: 0.9511 - distillation_loss: 0.7557 - val_accuracy: 0.6757 - val_student_loss: 0.9545 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7109 - student_loss: 0.9475 - distillation_loss: 0.7481 - val_accuracy: 0.6730 - val_student_loss: 0.9825 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7215 - student_loss: 0.9351 - distillation_loss: 0.7280 - val_accuracy: 0.6921 - val_student_loss: 0.9619 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7302 - student_loss: 0.9222 - distillation_loss: 0.7163 - val_accuracy: 0.6975 - val_student_loss: 0.9428 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7396 - student_loss: 0.9096 - distillation_loss: 0.6955 - val_accuracy: 0.6540 - val_student_loss: 0.9995 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7139 - student_loss: 0.9444 - distillation_loss: 0.7408 - val_accuracy: 0.6866 - val_student_loss: 0.9921 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7299 - student_loss: 0.9206 - distillation_loss: 0.7074 - val_accuracy: 0.7003 - val_student_loss: 0.9216 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7284 - student_loss: 0.9190 - distillation_loss: 0.7027 - val_accuracy: 0.7139 - val_student_loss: 0.9212 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7411 - student_loss: 0.8914 - distillation_loss: 0.6723 - val_accuracy: 0.6948 - val_student_loss: 0.9667 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7448 - student_loss: 0.8882 - distillation_loss: 0.6628 - val_accuracy: 0.7302 - val_student_loss: 0.9225 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7460 - student_loss: 0.8770 - distillation_loss: 0.6519 - val_accuracy: 0.7057 - val_student_loss: 0.9349 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7484 - student_loss: 0.8701 - distillation_loss: 0.6434 - val_accuracy: 0.7439 - val_student_loss: 0.9058 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7439 - student_loss: 0.8798 - distillation_loss: 0.6557 - val_accuracy: 0.7248 - val_student_loss: 0.9145 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7584 - student_loss: 0.8603 - distillation_loss: 0.6294 - val_accuracy: 0.7411 - val_student_loss: 0.9024 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7566 - student_loss: 0.8687 - distillation_loss: 0.6442 - val_accuracy: 0.7057 - val_student_loss: 0.9885 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 14s 1s/step - accuracy: 0.7445 - student_loss: 0.8744 - distillation_loss: 0.6481 - val_accuracy: 0.7221 - val_student_loss: 0.9148 - val_distillation_loss: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "deit_tiny = ViTDistilled()\n",
        "deit_distiller = DeiT(student=deit_tiny, teacher=bit_teacher_flowers)\n",
        "\n",
        "lr_scaled = (BASE_LR / 512) * BATCH_SIZE\n",
        "deit_distiller.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(weight_decay=WEIGHT_DECAY, learning_rate=lr_scaled),\n",
        "    metrics=[\"accuracy\"],\n",
        "    student_loss_fn=keras.losses.CategoricalCrossentropy(\n",
        "        from_logits=True, label_smoothing=0.1\n",
        "    ),\n",
        "    distillation_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "_ = deit_distiller.fit(train_dataset, validation_data=val_dataset, epochs=NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = deit_distiller.evaluate(val_dataset, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNaq7xFuGBoq",
        "outputId": "4816e182-9c8e-462e-e001-bd5ee64a305e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 64ms/step - accuracy: 0.7221 - student_loss: 0.9148 - distillation_loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on CIFAR10\n",
        "Just a trial, as the teacher is ResNet trained on tf_flowers"
      ],
      "metadata": {
        "id": "hu6ymCo7JlGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "train_dataset, val_dataset = tfds.load(\n",
        "    \"cifar10\", split=[\"train\", \"test\"], as_supervised=True\n",
        ")\n",
        "num_train = train_dataset.cardinality()\n",
        "num_val = val_dataset.cardinality()\n",
        "print(f\"Number of training examples: {num_train}\")\n",
        "print(f\"Number of validation examples: {num_val}\")\n",
        "\n",
        "train_dataset = prepare_dataset(train_dataset, is_training=True)\n",
        "val_dataset = prepare_dataset(val_dataset, is_training=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haNiq07kJeD2",
        "outputId": "54e6e04f-cd3f-490b-9623-f91b4cf27ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 50000\n",
            "Number of validation examples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deit_tiny = ViTDistilled()\n",
        "deit_distiller = DeiT(student=deit_tiny, teacher=bit_teacher_flowers)\n",
        "\n",
        "lr_scaled = (BASE_LR / 512) * BATCH_SIZE\n",
        "deit_distiller.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(weight_decay=WEIGHT_DECAY, learning_rate=lr_scaled),\n",
        "    metrics=[\"accuracy\"],\n",
        "    student_loss_fn=keras.losses.CategoricalCrossentropy(\n",
        "        from_logits=True, label_smoothing=0.1\n",
        "    ),\n",
        "    distillation_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "_ = deit_distiller.fit(train_dataset, validation_data=val_dataset, epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD_tG_EDJe6Z",
        "outputId": "912f750b-e00b-4710-ca6a-7ed79ea94fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "196/196 [==============================] - 256s 1s/step - accuracy: 0.1028 - student_loss: 2.2893 - distillation_loss: 1.2114 - val_accuracy: 0.1111 - val_student_loss: 3.1307 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1199 - student_loss: 2.0584 - distillation_loss: 1.1174 - val_accuracy: 0.1560 - val_student_loss: 3.1661 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1370 - student_loss: 1.9139 - distillation_loss: 1.0359 - val_accuracy: 0.1478 - val_student_loss: 3.1317 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1561 - student_loss: 1.7716 - distillation_loss: 0.9909 - val_accuracy: 0.1569 - val_student_loss: 3.1844 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1704 - student_loss: 1.6513 - distillation_loss: 0.9617 - val_accuracy: 0.1642 - val_student_loss: 3.1209 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1761 - student_loss: 1.5485 - distillation_loss: 0.9494 - val_accuracy: 0.1722 - val_student_loss: 3.0686 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1850 - student_loss: 1.4642 - distillation_loss: 0.9248 - val_accuracy: 0.2099 - val_student_loss: 2.9485 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1886 - student_loss: 1.4074 - distillation_loss: 0.9073 - val_accuracy: 0.1997 - val_student_loss: 2.9465 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1904 - student_loss: 1.3599 - distillation_loss: 0.8955 - val_accuracy: 0.1925 - val_student_loss: 2.9440 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1946 - student_loss: 1.3233 - distillation_loss: 0.8836 - val_accuracy: 0.1979 - val_student_loss: 2.8550 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1972 - student_loss: 1.2916 - distillation_loss: 0.8805 - val_accuracy: 0.1975 - val_student_loss: 2.8436 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.1980 - student_loss: 1.2652 - distillation_loss: 0.8688 - val_accuracy: 0.1848 - val_student_loss: 2.9902 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2021 - student_loss: 1.2392 - distillation_loss: 0.8638 - val_accuracy: 0.2223 - val_student_loss: 2.7798 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2041 - student_loss: 1.2153 - distillation_loss: 0.8516 - val_accuracy: 0.1964 - val_student_loss: 2.8623 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2106 - student_loss: 1.1965 - distillation_loss: 0.8519 - val_accuracy: 0.2310 - val_student_loss: 2.7626 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2062 - student_loss: 1.1738 - distillation_loss: 0.8385 - val_accuracy: 0.2044 - val_student_loss: 2.9550 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2116 - student_loss: 1.1440 - distillation_loss: 0.8382 - val_accuracy: 0.2222 - val_student_loss: 2.7813 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2149 - student_loss: 1.1358 - distillation_loss: 0.8287 - val_accuracy: 0.2125 - val_student_loss: 2.7965 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2146 - student_loss: 1.1140 - distillation_loss: 0.8210 - val_accuracy: 0.2108 - val_student_loss: 2.7651 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2179 - student_loss: 1.1122 - distillation_loss: 0.8173 - val_accuracy: 0.2164 - val_student_loss: 2.9333 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2155 - student_loss: 1.0925 - distillation_loss: 0.8120 - val_accuracy: 0.2274 - val_student_loss: 2.7904 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2219 - student_loss: 1.0780 - distillation_loss: 0.8099 - val_accuracy: 0.2099 - val_student_loss: 2.8119 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2212 - student_loss: 1.0683 - distillation_loss: 0.8031 - val_accuracy: 0.2043 - val_student_loss: 2.8219 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2205 - student_loss: 1.0491 - distillation_loss: 0.7955 - val_accuracy: 0.2257 - val_student_loss: 2.9720 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2225 - student_loss: 1.0417 - distillation_loss: 0.7921 - val_accuracy: 0.2206 - val_student_loss: 2.8257 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2273 - student_loss: 1.0287 - distillation_loss: 0.7978 - val_accuracy: 0.2496 - val_student_loss: 2.9265 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2260 - student_loss: 1.0287 - distillation_loss: 0.7885 - val_accuracy: 0.2221 - val_student_loss: 2.9449 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2284 - student_loss: 1.0134 - distillation_loss: 0.7851 - val_accuracy: 0.2213 - val_student_loss: 3.0387 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2299 - student_loss: 0.9991 - distillation_loss: 0.7843 - val_accuracy: 0.2209 - val_student_loss: 3.0734 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2287 - student_loss: 0.9946 - distillation_loss: 0.7779 - val_accuracy: 0.2138 - val_student_loss: 2.9707 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2306 - student_loss: 0.9882 - distillation_loss: 0.7755 - val_accuracy: 0.2136 - val_student_loss: 3.2729 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2300 - student_loss: 0.9802 - distillation_loss: 0.7700 - val_accuracy: 0.2006 - val_student_loss: 3.1552 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2291 - student_loss: 0.9716 - distillation_loss: 0.7666 - val_accuracy: 0.2542 - val_student_loss: 3.2031 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2319 - student_loss: 0.9628 - distillation_loss: 0.7631 - val_accuracy: 0.2386 - val_student_loss: 3.0986 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2319 - student_loss: 0.9595 - distillation_loss: 0.7631 - val_accuracy: 0.2131 - val_student_loss: 3.2468 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2344 - student_loss: 0.9543 - distillation_loss: 0.7621 - val_accuracy: 0.2060 - val_student_loss: 3.1994 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2331 - student_loss: 0.9387 - distillation_loss: 0.7549 - val_accuracy: 0.2176 - val_student_loss: 3.1883 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2340 - student_loss: 0.9328 - distillation_loss: 0.7520 - val_accuracy: 0.2357 - val_student_loss: 2.9848 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2348 - student_loss: 0.9310 - distillation_loss: 0.7534 - val_accuracy: 0.2326 - val_student_loss: 3.0136 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2352 - student_loss: 0.9327 - distillation_loss: 0.7483 - val_accuracy: 0.2313 - val_student_loss: 3.1348 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2379 - student_loss: 0.9212 - distillation_loss: 0.7441 - val_accuracy: 0.2121 - val_student_loss: 3.3057 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2376 - student_loss: 0.9165 - distillation_loss: 0.7475 - val_accuracy: 0.2240 - val_student_loss: 3.3757 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2383 - student_loss: 0.9141 - distillation_loss: 0.7384 - val_accuracy: 0.2071 - val_student_loss: 3.6257 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2386 - student_loss: 0.9023 - distillation_loss: 0.7366 - val_accuracy: 0.2170 - val_student_loss: 3.5638 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2361 - student_loss: 0.9051 - distillation_loss: 0.7362 - val_accuracy: 0.2178 - val_student_loss: 3.3040 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2428 - student_loss: 0.8948 - distillation_loss: 0.7364 - val_accuracy: 0.2037 - val_student_loss: 3.4367 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2381 - student_loss: 0.8963 - distillation_loss: 0.7295 - val_accuracy: 0.2350 - val_student_loss: 3.3529 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2422 - student_loss: 0.8875 - distillation_loss: 0.7331 - val_accuracy: 0.2247 - val_student_loss: 3.4408 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 213s 1s/step - accuracy: 0.2400 - student_loss: 0.8841 - distillation_loss: 0.7291 - val_accuracy: 0.2059 - val_student_loss: 3.3769 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 214s 1s/step - accuracy: 0.2382 - student_loss: 0.8799 - distillation_loss: 0.7211 - val_accuracy: 0.2332 - val_student_loss: 3.4889 - val_distillation_loss: 0.0000e+00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}